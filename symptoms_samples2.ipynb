{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 670,
      "metadata": {
        "id": "l2rXR-0-uT21"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,precision_score,recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, RFE, SelectFromModel,chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 671,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the train.csv by removing the\n",
        "# last column since it's an empty column\n",
        "training_data = pd.read_csv(\"data/symptoms_Data_Training.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data.drop(training_data.columns[-1], axis=1,inplace=True)\n",
        "training_data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 674,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_processing(data):\n",
        "    # List of target labels\n",
        "    target_labels = [\"Diabetes\", \"Hypertension\"]\n",
        "\n",
        "    # 1. Change all rows not in target labels to \"not ill\"\n",
        "    data[\"prognosis\"] = data[\"prognosis\"].apply(\n",
        "        lambda x: x if x in target_labels else \"not ill\"\n",
        "    )\n",
        "\n",
        "    # Separate majority and minority classes\n",
        "    majority = data[data[\"prognosis\"] == \"not ill\"]\n",
        "    minority_Hypertension = data[data[\"prognosis\"] == \"Hypertension\"]\n",
        "    minority_Diabetes = data[data[\"prognosis\"] == \"Diabetes\"]\n",
        "\n",
        "    # Upsample minority class\n",
        "    minority_upsampled_Diabetes = resample(\n",
        "        minority_Diabetes, replace=True, n_samples=len(majority), random_state=42\n",
        "    )\n",
        "    minority_upsampled_Hypertension = resample(\n",
        "        minority_Hypertension, replace=True, n_samples=len(majority), random_state=42\n",
        "    )\n",
        "\n",
        "    # Combine with majority class\n",
        "    data = pd.concat(\n",
        "        [majority, minority_upsampled_Diabetes, minority_upsampled_Hypertension]\n",
        "    )\n",
        "\n",
        "    print(data[\"prognosis\"].value_counts())\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data_processing(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data types and non-null counts\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary for binary columns\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values in each column\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in data.columns[:-1]:  # Exclude the last object column\n",
        "    print(f\"{col}:\\n{data[col].value_counts()}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 681,
      "metadata": {},
      "outputs": [],
      "source": [
        "# correlation_matrix = data.iloc[:, :-1].corr()\n",
        "# # Create a heatmap of the correlation matrix\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "# plt.title('Correlation Matrix for Iris Dataset')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 682,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
        "# plt.title(\"Correlation Matrix of Binary Features\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 683,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Bar plots for each binary feature grouped by the Category\n",
        "# for col in data.columns[:-1]:\n",
        "#     sns.barplot(x='prognosis', y=col, data=data)\n",
        "#     plt.title(f\"Distribution of {col} by prognosis\")\n",
        "#     plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "nn3TJZs2ua-7",
        "outputId": "917b29ca-7206-4abb-eac0-0e15cafc10fb"
      },
      "outputs": [],
      "source": [
        "# Checking whether the dataset is balanced or not\n",
        "disease_counts = data[\"prognosis\"].value_counts()\n",
        "temp_df = pd.DataFrame({\n",
        "    \"Disease\": disease_counts.index,\n",
        "    \"Counts\": disease_counts.values\n",
        "})\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.barplot(x = \"Disease\", y = \"Counts\", data = temp_df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 685,
      "metadata": {
        "id": "Q3RVFtEmuc44"
      },
      "outputs": [],
      "source": [
        "# Encoding the target value into numerical\n",
        "# value using LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "data[\"prognosis\"] = encoder.fit_transform(data[\"prognosis\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 686,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S184zJ0ud42",
        "outputId": "04b85f91-764f-40f8-dccc-d40331b88ddb"
      },
      "outputs": [],
      "source": [
        "XX = data.iloc[:,:-1]\n",
        "y = data.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sama\n",
        "\n",
        "# Assume X is your feature matrix and y is your target variable\n",
        "selector = SelectKBest(score_func=chi2, k=10)  # Select top 10 features\n",
        "X = selector.fit_transform(XX, y)\n",
        "\n",
        "# Get scores and feature indices\n",
        "scores = selector.scores_\n",
        "selected_features = selector.get_support(indices=True)\n",
        "print(\"Selected feature indices:\", selected_features)\n",
        "# print(\"Feature scores:\", scores)\n",
        "selected_columns = XX.columns[selector.get_support()].tolist()\n",
        "print(\"Selected columns:\", selected_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test =train_test_split(\n",
        "  X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test: {X_test.shape}, {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBLoimfwugoq",
        "outputId": "c88b344e-4ee6-4d7e-a1d2-7a19d0078fb6"
      },
      "outputs": [],
      "source": [
        "# Defining scoring metric for k-fold cross validation\n",
        "def cv_scoring(estimator, X, y):\n",
        "    return accuracy_score(y, estimator.predict(X))\n",
        "\n",
        "# Initializing Models\n",
        "models = {\n",
        "    \"SVC\":SVC(),\n",
        "    \"Gaussian NB\":GaussianNB(),\n",
        "    \"Random Forest\":RandomForestClassifier(random_state=18),\n",
        "    \"Decision Tree\":DecisionTreeClassifier(criterion=\"gini\")\n",
        "}\n",
        "\n",
        "# Producing cross validation score for the models\n",
        "for model_name in models:\n",
        "    model = models[model_name]\n",
        "    scores = cross_val_score(model, X, y, cv = 10,\n",
        "                             n_jobs = -1,\n",
        "                             scoring = cv_scoring)\n",
        "    print(\"==\"*30)\n",
        "    print(model_name)\n",
        "    print(f\"Scores: {scores}\")\n",
        "    print(f\"Mean Score: {np.mean(scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LY1Soe9TujRa",
        "outputId": "70af95e1-6457-4a17-90f6-18444741390b"
      },
      "outputs": [],
      "source": [
        "# Training and testing SVM Classifier\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "preds = svm_model.predict(X_test)\n",
        "\n",
        "print(\n",
        "    f\"Accuracy on train data by SVM Classifier: {accuracy_score(y_train, svm_model.predict(X_train))*100}\\\n",
        "     precision on train data by SVM Classifier: {precision_score(y_train, svm_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     recall score on train data by SVM Classifier: {recall_score(y_train, svm_model.predict(X_train),average=\"weighted\")*100} \\\n",
        "     f1 score on train data by SVM Classifier: {f1_score(y_train, svm_model.predict(X_train),average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Accuracy on test data by SVM Classifier: {accuracy_score(y_test, preds)*100}\\\n",
        "     precision_score on test data by SVM Classifier: {precision_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     recall_score on test data by SVM Classifier: {recall_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     f1_score on test data by SVM Classifier: {f1_score(y_test, preds,average=\"weighted\")*100}\"\n",
        ")\n",
        "# cf_matrix = confusion_matrix(y_test, preds)\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.heatmap(cf_matrix, annot=True)\n",
        "# plt.title(\"Confusion Matrix for SVM Classifier on Test Data\")\n",
        "# plt.show()\n",
        "\n",
        "# Training and testing Naive Bayes Classifier\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "preds = nb_model.predict(X_test)\n",
        "print(\n",
        "    f\"Accuracy on train data by GaussianNB Classifier: {accuracy_score(y_train, nb_model.predict(X_train))*100}\\\n",
        "     precision_score on train data by GaussianNB Classifier: {precision_score(y_train, nb_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     recall_score on train data by GaussianNB Classifier: {recall_score(y_train, nb_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     f1_score on train data by GaussianNB Classifier: {f1_score(y_train, nb_model.predict(X_train),average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Accuracy on test data by Naive Bayes Classifier: {accuracy_score(y_test, preds)*100}\\\n",
        "     precision_score on test data by Naive Bayes Classifier: {precision_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     recall_score on test data by Naive Bayes Classifier: {recall_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     f1_score on test data by Naive Bayes Classifier: {f1_score(y_test, preds,average=\"weighted\")*100}\"\n",
        ")\n",
        "# cf_matrix = confusion_matrix(y_test, preds)\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.heatmap(cf_matrix, annot=True)\n",
        "# plt.title(\"Confusion Matrix for Naive Bayes Classifier on Test Data\")\n",
        "# plt.show()\n",
        "\n",
        "# Training and testing Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=18)\n",
        "rf_model.fit(X_train, y_train)\n",
        "preds = rf_model.predict(X_test)\n",
        "print(\n",
        "    f\"Accuracy on train data by Random Forest Classifier: {accuracy_score(y_train, rf_model.predict(X_train))*100}\\\n",
        "     precision_score on train data by Random Forest Classifier: {precision_score(y_train, rf_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     recall_score on train data by Random Forest Classifier: {recall_score(y_train, rf_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     f1_score on train data by Random Forest Classifier: {f1_score(y_train, rf_model.predict(X_train),average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Accuracy on test data by Random Forest Classifier: {accuracy_score(y_test, preds)*100}\\\n",
        "     precision_score on test data by Random Forest Classifier: {precision_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     recall_score on test data by Random Forest Classifier: {recall_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     f1_score on test data by Random Forest Classifier: {f1_score(y_test, preds,average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "# Training and testing Random Forest Classifier\n",
        "dt_model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "dt_model.fit(X_train, y_train)\n",
        "preds = dt_model.predict(X_test)\n",
        "print(\n",
        "    f\"Accuracy on train data by Random Forest Classifier: {accuracy_score(y_train, dt_model.predict(X_train))*100}\\\n",
        "     precision_score on train data by Random Forest Classifier: {precision_score(y_train, dt_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     recall_score on train data by Random Forest Classifier: {recall_score(y_train, dt_model.predict(X_train),average=\"weighted\")*100}\\\n",
        "     f1_score on train data by Random Forest Classifier: {f1_score(y_train, dt_model.predict(X_train),average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Accuracy on test data by Random Forest Classifier: {accuracy_score(y_test, preds)*100}\\\n",
        "     precision_score on test data by Random Forest Classifier: {precision_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     recall_score on test data by Random Forest Classifier: {recall_score(y_test, preds,average=\"weighted\")*100}\\\n",
        "     f1_score on test data by Random Forest Classifier: {f1_score(y_test, preds,average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "# cf_matrix = confusion_matrix(y_test, preds)\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.heatmap(cf_matrix, annot=True)\n",
        "# plt.title(\"Confusion Matrix for Random Forest Classifier on Test Data\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test data preprocessing\n",
        "test_data = pd.read_csv(\"data/symptoms_Data_Testing.csv\")\n",
        "test_data = data_processing(test_data)\n",
        "test_X = test_data.iloc[:, :-1]\n",
        "test_Y = encoder.transform(test_data.iloc[:, -1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 694,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_X = selector.fit_transform(test_X, test_Y)\n",
        "selected_features = selector.get_support(indices=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "iSOQ1WAoulOX",
        "outputId": "7fb5a6a9-6e4f-4409-cad8-cde1bf2871fb"
      },
      "outputs": [],
      "source": [
        "# Training the models on whole data\n",
        "final_svm_model = SVC()\n",
        "final_nb_model = GaussianNB()\n",
        "final_rf_model = RandomForestClassifier(random_state=18)\n",
        "final_dt_model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "final_svm_model.fit(X, y)\n",
        "final_nb_model.fit(X, y)\n",
        "final_rf_model.fit(X, y)\n",
        "final_dt_model.fit(X, y)\n",
        "\n",
        "# Making prediction by take mode of predictions\n",
        "# made by all the classifiers\n",
        "svm_preds = final_svm_model.predict(test_X)\n",
        "nb_preds = final_nb_model.predict(test_X)\n",
        "rf_preds = final_rf_model.predict(test_X)\n",
        "dt_preds = final_dt_model.predict(test_X)\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "final_preds = [\n",
        "    stats.mode([i, j, k])[0] for i, j, k in zip(svm_preds, dt_preds, rf_preds)\n",
        "]\n",
        "\n",
        "print(\n",
        "    f\"Accuracy on Test dataset by the combined model: {accuracy_score(test_Y, final_preds)*100}\\\n",
        "     precision_score on Test dataset by the combined model: {precision_score(test_Y, final_preds,average=\"weighted\")*100}\\\n",
        "     recall_score on Test dataset by the combined model: {recall_score(test_Y, final_preds,average=\"weighted\")*100}\\\n",
        "     f1_score on Test dataset by the combined model: {f1_score(test_Y, final_preds,average=\"weighted\")*100}\"\n",
        ")\n",
        "\n",
        "# cf_matrix = confusion_matrix(test_Y, final_preds)\n",
        "# plt.figure(figsize=(12, 8))\n",
        "\n",
        "# sns.heatmap(cf_matrix, annot=True)\n",
        "# plt.title(\"Confusion Matrix for Combined Model on Test Dataset\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHYnvMYRund0",
        "outputId": "092dc46e-ddf8-4dc7-a367-5df5f57467b9"
      },
      "outputs": [],
      "source": [
        "symptoms = selected_columns\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# Randomly select 3 values\n",
        "if len(selected_columns) >= 3:\n",
        "    random_values = random.sample(selected_columns, 3)\n",
        "    print(\"Randomly selected columns:\", random_values)\n",
        "else:\n",
        "    print(\"The list has fewer than 3 elements.\")\n",
        "\n",
        "# Creating a symptom index dictionary to encode the\n",
        "# input symptoms into numerical form\n",
        "symptom_index = {}\n",
        "for index, value in enumerate(symptoms):\n",
        "    symptom_index[value] = index\n",
        "\n",
        "data_dict = {\"symptom_index\": symptom_index, \"predictions_classes\": encoder.classes_}\n",
        "\n",
        "\n",
        "# Defining the Function\n",
        "# Input: string containing symptoms separated by commas\n",
        "# Output: Generated predictions by models\n",
        "def predictDisease(symptoms):\n",
        "    # creating input data for the models\n",
        "    input_data = [0] * len(data_dict[\"symptom_index\"])\n",
        "    for symptom in symptoms:\n",
        "        index = data_dict[\"symptom_index\"][symptom]\n",
        "        input_data[index] = 1\n",
        "\n",
        "    # reshaping the input data and converting it\n",
        "    # into suitable format for model predictions\n",
        "    input_data = np.array(input_data).reshape(1, -1)\n",
        "\n",
        "    # generating individual outputs\n",
        "    rf_prediction = data_dict[\"predictions_classes\"][\n",
        "        final_rf_model.predict(input_data)[0]\n",
        "    ]\n",
        "    svm_prediction = data_dict[\"predictions_classes\"][\n",
        "        final_svm_model.predict(input_data)[0]\n",
        "    ]\n",
        "    dt_prediction = data_dict[\"predictions_classes\"][\n",
        "        final_dt_model.predict(input_data)[0]\n",
        "    ]\n",
        "\n",
        "    # making final prediction by taking mode of all predictions\n",
        "    # Use statistics.mode instead of scipy.stats.mode\n",
        "    import statistics\n",
        "\n",
        "    final_prediction = statistics.mode([rf_prediction, svm_prediction])\n",
        "    predictions = {\n",
        "        \"rf_model_prediction\": rf_prediction,\n",
        "        \"svm_model_prediction\": svm_prediction,\n",
        "        \"dt_model_prediction\": dt_prediction,\n",
        "        \"final_prediction\": final_prediction,\n",
        "    }\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Testing the function\n",
        "print(\n",
        "    predictDisease(random_values)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML_sourse",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
